libibverbs: Warning: RLIMIT_MEMLOCK is 32768 bytes.
    This will severely limit memory registrations.
libibverbs: Warning: RLIMIT_MEMLOCK is 32768 bytes.
    This will severely limit memory registrations.
--------------------------------------------------------------------------
The OpenFabrics (openib) BTL failed to initialize while trying to
allocate some locked memory.  This typically can indicate that the
memlock limits are set too low.  For most HPC installations, the
memlock limits should be set to "unlimited".  The failure occured
here:

  Local host:    node39.cluster.tld
  OMPI source:   btl_openib_component.c:1066
  Function:      ompi_free_list_init_ex_new()
  Device:        mthca0
  Memlock limit: 32768

You may need to consult with your system administrator to get this
problem fixed.  This FAQ entry on the Open MPI web site may also be
helpful:

    http://www.open-mpi.org/faq/?category=openfabrics#ib-locked-pages
--------------------------------------------------------------------------
--------------------------------------------------------------------------
WARNING: There was an error initializing an OpenFabrics device.

  Local host:   node39.cluster.tld
  Local device: mthca0
--------------------------------------------------------------------------
libibverbs: Warning: RLIMIT_MEMLOCK is 32768 bytes.
    This will severely limit memory registrations.
libibverbs: Warning: RLIMIT_MEMLOCK is 32768 bytes.
    This will severely limit memory registrations.
libibverbs: Warning: RLIMIT_MEMLOCK is 32768 bytes.
    This will severely limit memory registrations.
libibverbs: Warning: RLIMIT_MEMLOCK is 32768 bytes.
    This will severely limit memory registrations.
libibverbs: Warning: RLIMIT_MEMLOCK is 32768 bytes.
    This will severely limit memory registrations.
libibverbs: Warning: RLIMIT_MEMLOCK is 32768 bytes.
    This will severely limit memory registrations.
[node47.cluster.tld:27222] 7 more processes have sent help message help-mpi-btl-openib.txt / init-fail-no-mem
[node47.cluster.tld:27222] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[node47.cluster.tld:27222] 7 more processes have sent help message help-mpi-btl-openib.txt / error in device init
forrtl: severe (41): insufficient virtual memory
Image              PC                Routine            Line        Source             
libintlc.so.5      00002AAAAEC4B9AA  Unknown               Unknown  Unknown
libintlc.so.5      00002AAAAEC4A4A6  Unknown               Unknown  Unknown
libifcoremt.so.5   00002AAAAE03803C  Unknown               Unknown  Unknown
libifcoremt.so.5   00002AAAADFA8282  Unknown               Unknown  Unknown
libifcoremt.so.5   00002AAAADFF8F1A  Unknown               Unknown  Unknown
libifcoremt.so.5   00002AAAADFF8D71  Unknown               Unknown  Unknown
dmbayes_chord      00000000004FB730  array_module_mp_r         358  array_utils.f90
dmbayes_chord      00000000004DE6DF  run_time_module_m         390  run_time_info.f90
dmbayes_chord      0000000000502C19  cluster_module_mp         310  clustering.f90
dmbayes_chord      00000000004BB5F3  nested_sampling_m         279  nested_sampling.F90
dmbayes_chord      00000000004AF7B1  nestwrapper_mp_ne          66  nestwrap.f90
dmbayes_chord      00000000004B1918  MAIN__                    261  driver_chord.f90
dmbayes_chord      000000000042D31C  Unknown               Unknown  Unknown
libc.so.6          0000003072A1D8A4  Unknown               Unknown  Unknown
dmbayes_chord      000000000042D229  Unknown               Unknown  Unknown
[node43.cluster.tld][[7931,1],34][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node43.cluster.tld][[7931,1],38][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] [node38.cluster.tld][[7931,1],72][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node38.cluster.tld][[7931,1],78][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] [node46.cluster.tld][[7931,1],9][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)[node39.cluster.tld][[7931,1],69][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node46.cluster.tld][[7931,1],15][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)

mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)[node37.cluster.tld][[7931,1],81][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node46.cluster.tld][[7931,1],11][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node45.cluster.tld][[7931,1],22][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node44.cluster.tld][[7931,1],24][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)

[node45.cluster.tld][[7931,1],17][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node44.cluster.tld][[7931,1],27][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node44.cluster.tld][[7931,1],31][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node42.cluster.tld][[7931,1],43][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node42.cluster.tld][[7931,1],46][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node38.cluster.tld][[7931,1],79][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] [node40.cluster.tld][[7931,1],50][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node40.cluster.tld][[7931,1],53][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node40.cluster.tld][[7931,1],55][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
[node41.cluster.tld][[7931,1],57][btl_tcp_frag.c:216:mca_btl_tcp_frag_recv] mca_btl_tcp_frag_recv: readv failed: Connection reset by peer (104)
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 27223 on
node node47.cluster.tld exiting without calling "finalize". This may
have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
